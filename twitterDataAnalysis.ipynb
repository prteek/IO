{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitterDataAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "575.85px",
        "left": "861px",
        "right": "20px",
        "top": "95px",
        "width": "561px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prteek/IO/blob/master/twitterDataAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nIvxqccGXSC4"
      },
      "source": [
        "# Twitter data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrfzB5IricKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This cell is not required to be executed (i.e. ignore any error) if Notebook is run locally or in Binder\n",
        "# Authorise and mount google drive to access code and data files\n",
        "\n",
        "project_folder = '/content/drive/My Drive/git_repos/IO/'\n",
        "\n",
        "import os\n",
        "\n",
        "if os.path.isdir('/content'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    if not(os.path.isdir(project_folder)):\n",
        "      os.makedirs(project_folder)\n",
        "      print(\"new project folder created\")\n",
        "\n",
        "    os.chdir(project_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jMnkb7EEXSC7",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "from twython import Twython\n",
        "from collections import Counter\n",
        "from geopy import Nominatim\n",
        "\n",
        "# Note if running from binder the text file below will give an \n",
        "try:\n",
        "    with open(\"twitter_credentials.txt\", \"r\") as f:\n",
        "        line_text = [line.strip() for line in f]\n",
        "except:\n",
        "    print(\"Note: The credentials file is not available on Git.\\n\"\n",
        "          \"If running the script on Binder, specify own app KEY and SECRET below \"\n",
        "          \"and the code should run without any issue.\\n\")\n",
        "    print(\"go to: https://developer.twitter.com/en/apps \\nand create an app to generate KEY and SECRET\\n\")\n",
        "    print(\"Binder will not store these keys and everything will be reset when the file is closed.\")\n",
        "    \n",
        "    \n",
        "CONSUMER_KEY         = line_text[0]\n",
        "CONSUMER_SECRET      = line_text[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FBHKzgHBXSDC"
      },
      "source": [
        "### Making a search query\n",
        "\n",
        "refer: https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets for formatting the search query and understanding results format.  \n",
        "\n",
        "Max. num of results restricted to 100 per search query so we loop over many times and make the same query.\n",
        "But to avoid the results from repeating, we change the max_id of search results after each iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJdkLQ7TXSDG",
        "colab": {}
      },
      "source": [
        "def find_tweets(search_string                 = \"\", # \"\" to search everything\n",
        "                location_of_interest          = \"London\",\n",
        "                radius_of_interest_in_km      = 20,\n",
        "                num_tweets_to_fetch           = 1000,\n",
        "                type_of_result                = \"all\", # all, mixed, recent or popular\n",
        "                c_key=CONSUMER_KEY, c_secret=CONSUMER_SECRET):\n",
        "\n",
        "    # initialisation\n",
        "    twitter        = Twython(c_key, c_secret)\n",
        "\n",
        "    tweets                = []\n",
        "    word_list             = []\n",
        "    hashtag_list          = []\n",
        "    retweet_count_list    = []\n",
        "    favorite_count_list   = []\n",
        "    tweet_url_list        = []\n",
        "\n",
        "    # Search area definition\n",
        "    geolocator        = Nominatim(user_agent='GoogleV3')\n",
        "    location          = geolocator.geocode(location_of_interest)\n",
        "    geo_code = str(location.latitude) + \",\" + str(location.longitude) + \",\" + str(radius_of_interest_in_km) + \"km\"\n",
        "\n",
        "\n",
        "    num_results_per_query = min([num_tweets_to_fetch, 100])\n",
        "\n",
        "    # In case there aren't enough results for the search term\n",
        "    max_attempts          = max(50, num_tweets_to_fetch//num_results_per_query*2) \n",
        "\n",
        "    print(\"fetching...\")   \n",
        "    for i in range(0,max_attempts):\n",
        "        if(num_tweets_to_fetch < len(tweets)):\n",
        "            break # we got all the tweets we asked for ... !!\n",
        "\n",
        "        #----------------------------------------------------------------#\n",
        "        # STEP 1: Query Twitter\n",
        "        # STEP 2: Save the returned tweets\n",
        "        # STEP 3: Get the next max_id\n",
        "        #----------------------------------------------------------------#\n",
        "\n",
        "        # STEP 1: Query Twitter\n",
        "        if(0 == i):\n",
        "            # Query twitter for data. \n",
        "            results = twitter.search(q=search_string, count=str(num_results_per_query), geocode=geo_code, \n",
        "                                     result_type=type_of_result)\n",
        "        else:\n",
        "            # After the first call we should have max_id from result of previous call. Pass it in query.\n",
        "            results = twitter.search(q=search_string,count=str(num_results_per_query), geocode=geo_code, \n",
        "                                     result_type=type_of_result,\n",
        "                                     include_entities='true',max_id=next_max_id)\n",
        "\n",
        "        # STEP 2: Save the returned tweets\n",
        "        for status in results['statuses']:        \n",
        "            user = status[\"user\"][\"screen_name\"].encode(\"utf-8\")\n",
        "            user = user.decode(\"utf-8\") # to convert the encoded byte type into string\n",
        "            text = status[\"text\"].encode(\"utf-8\")\n",
        "            text = text.decode(\"utf-8\") # to convert the encoded byte type into string\n",
        "            for word in text.split():\n",
        "                word_list.append(word)\n",
        "\n",
        "                if word.startswith(\"#\"):\n",
        "                    hashtag_list.append(word)\n",
        "\n",
        "            tweets.append(text) # Keep track of number of tweets\n",
        "            favorite_count_list.append(status[\"favorite_count\"])\n",
        "            retweet_count_list.append(status[\"retweet_count\"])\n",
        "            tweet_url_list.append(\"https://twitter.com/i/web/status/\"+status[\"id_str\"])\n",
        "\n",
        "        # STEP 3: Get the next max_id\n",
        "        try:\n",
        "            # Parse the data returned to get max_id to be passed in consequent call.\n",
        "            next_results_url_params = results['search_metadata']['next_results']\n",
        "            next_max_id = next_results_url_params.split('max_id=')[1].split('&')[0]\n",
        "        except:\n",
        "            # No more next pages\n",
        "            break\n",
        "    \n",
        "    print(\"...Done\")\n",
        "    return tweets, hashtag_list, tweet_url_list, retweet_count_list, word_list, favorite_count_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GMeQxdVrXSDK"
      },
      "source": [
        "### Search for tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T5rcUJGbXSDL",
        "outputId": "bdb53e7a-abb1-4434-ee64-fa24580b7801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "search_string                 = input(\"Search String:\") # \"\" to search everything\n",
        "location_of_interest          = \"London\"\n",
        "radius_of_interest_in_km      = 20\n",
        "num_tweets_to_fetch           = 1000\n",
        "type_of_result                = \"all\" # all, mixed, recent or popular\n",
        "\n",
        "# Search area definition\n",
        "geolocator        = Nominatim(user_agent='GoogleV3')\n",
        "location                      = geolocator.geocode(location_of_interest)\n",
        "\n",
        "tweets, hashtag_list, tweet_url_list, retweet_count_list, word_list, favorite_count_list = find_tweets(search_string, \n",
        "            location_of_interest, \n",
        "            radius_of_interest_in_km,\n",
        "            num_tweets_to_fetch,\n",
        "            type_of_result,\n",
        "            c_key=CONSUMER_KEY, c_secret=CONSUMER_SECRET)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search String:\n",
            "fetching...\n",
            "...Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-tgbWvwlXSDR"
      },
      "source": [
        "### Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u9wAN90sXSDS",
        "outputId": "830304bf-426b-4752-c686-d9017c4369a8",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "print(location,\"\\n\")\n",
        "print(\"Number of tweets fetched:\", len(tweets))\n",
        "\n",
        "print(\"\\n Top Hashtags:\")\n",
        "c = Counter(hashtag_list)\n",
        "for tags, count in c.most_common(5):\n",
        "    print(tags,count)\n",
        "    \n",
        "# print(\"\\n Most common words:\")\n",
        "# c = Counter(word_list)\n",
        "# for tags, count in c.most_common(6):\n",
        "#     print(tags,count)\n",
        "\n",
        "print(\"\\n\")\n",
        "max_retweet_index = sorted(range(len(retweet_count_list)), key=lambda x: -retweet_count_list[x])[0]\n",
        "                           \n",
        "most_retweeted    = tweets[max_retweet_index]\n",
        "max_retweet_count = retweet_count_list[max_retweet_index]\n",
        "max_retweet_url   = tweet_url_list[max_retweet_index]   \n",
        "print(\"(most) Retweeted:\", max_retweet_count, \"\\n\", most_retweeted, \"\\n\\n\", \"tweet link:\", max_retweet_url)\n",
        "\n",
        "print(\"\\n\")\n",
        "max_favorite_index = sorted(range(len(favorite_count_list)), key=lambda x: -favorite_count_list[x])[0]\n",
        "most_favorite      = tweets[max_favorite_index]\n",
        "max_favorite_count = favorite_count_list[max_favorite_index]\n",
        "max_favorite_url   = tweet_url_list[max_favorite_index] \n",
        "                            \n",
        "print(\"(most) Favorited:\", max_favorite_count, \"\\n\", most_favorite, \"\\n\\n\", \"tweet link:\", max_favorite_url)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "London, Greater London, England, SW1A 2DX, United Kingdom \n",
            "\n",
            "Number of tweets fetched: 1079\n",
            "\n",
            " Top Hashtags:\n",
            "#DemDebate 10\n",
            "#بسفارتنا 3\n",
            "#books 3\n",
            "#IOpipe 2\n",
            "#WhenTheySeeUs. 2\n",
            "\n",
            "\n",
            "(most) Retweeted: 48247 \n",
            " RT @illucifer: THERE CAN ONLY BE ONE https://t.co/CXU8GbKBH5 \n",
            "\n",
            " tweet link: https://twitter.com/i/web/status/1156363657800028162\n",
            "\n",
            "\n",
            "(most) Favorited: 5 \n",
            " Is today the day? https://t.co/V70pDQKptq \n",
            "\n",
            " tweet link: https://twitter.com/i/web/status/1156363714725126144\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}