import streamlit as st

def run():
    st.title("[The Dilemma of Autonomous Vehicles](https://t.co/BlMT9mMc1K)")

    st.markdown("""
Every year 35000 people die in the US alone in car accidents and about 1.2m in the world (DoT U.S.)

The social opinion about adoption of AVs is split. Most people are of the opinion that we must wait until the technology is safe and perfect. Maybe it can be 90% or even 99% safe in few years (say 2030) but to reach to 100% it can take about 50 more years of research. That would mean additional 60m more deaths at current rate until 2070.
Unnecessary delays may lower the impact this technology can have.

A concern regarding the safety and the ethical conundrum involved is clearly highlighted in a scenario where a car’s brakes failed and it can now encounter the following 3 options:  

1. Continue straight and hit many pedestrians crossing the road  
2. Swerve and hit a bystander  
3. Swerve and hit a wall killing the passenger  

(Obviously these are un-realistic and the car will calculate the probability of collision in effect making tradeoffs. But, often times making tradeoffs require ethical considerations).  
And however unrealistic, this scenario must be discussed to not avoid deliberating on the point that there would be some necessary ethical decisions for AVs to make.  

Of the above choices what ethical decision should the car make ?  

### Ideas from philosophy

A survey to estimate what is the societal opinion on this matter was performed by Jean-Francois Bonnefon and Azim Shariff which gave people 2 options to choose from based on ideas inspired by 2 philosophers: **Jeremy Bentham and Immanuel Kant**  

Bentham’s point of view holds that car should follow utilitarian ethics: it should take the action that minimises total harm, even if it means killing a bystander or the passenger.  

Kant’s point of view says that car should follow duty bound principles, like “Thou shalt not kill”. So it should not take any action that explicitly harms a human being and it should follow its natural course even if that’s going to harm more people.  
(Kant’s point of view is kind of invalid by the fact that it involves car to not make a decision at the end or eliminate decisions until 1 is left. However, for cars to be self driving even to continue straight ahead the car needs to make a decision whether it is going to collide or should it safely change lane etc.)

Most people taking the survey agree with Bentham’s point of view that cars should minimise total harm. However, when asked  whether they would like to purchase such a car, they said “Absolutely not.”  

They would like to buy cars that protect them at all cost, but they want everybody else to buy cars that minimise harm.  

This is pretty much the same case even for reducing carbon emissions to mitigate climate change.  


""")
    
    
    st.markdown(""" ###
    ---
    [Prateek](https://www.linkedin.com/in/prteek/ "LinkedIn")  
    [Repository](https://github.com/prteek/IO/ "Github")

    """)